{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1rjvNpcPzAzm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sPyiSi4TvP37"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mainoahmuna/Google Drive/My Drive/Team-Fermata-Energy/processed_data/processed_weather_and_load/32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/mainoahmuna/Google Drive/My Drive/Team-Fermata-Energy/processed_data/processed_weather_and_load/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "uXSjE71SzaiL",
    "outputId": "6b4c67e3-69da-421b-8765-ebdb290b521c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>out.electricity.total.energy_consumption</th>\n",
       "      <th>Dry Bulb Temperature [°C]</th>\n",
       "      <th>Relative Humidity [%]</th>\n",
       "      <th>heat_index</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>max_load_hourly</th>\n",
       "      <th>max_temp_hourly</th>\n",
       "      <th>min_temp_hourly</th>\n",
       "      <th>bldg_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.420033</td>\n",
       "      <td>-6.10</td>\n",
       "      <td>42.781847</td>\n",
       "      <td>21.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-6.55</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>43.350762</td>\n",
       "      <td>20.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-6.55</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>43.919676</td>\n",
       "      <td>20.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-6.55</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.55</td>\n",
       "      <td>44.488591</td>\n",
       "      <td>20.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-6.55</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>45.057505</td>\n",
       "      <td>19.94</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.476113</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  out.electricity.total.energy_consumption  Dry Bulb Temperature [°C]  \\\n",
       "0      0                                  5.420033                      -6.10   \n",
       "1      1                                  5.476113                      -6.25   \n",
       "2      2                                  5.476113                      -6.40   \n",
       "3      3                                  5.476113                      -6.55   \n",
       "4      4                                  5.476113                      -6.70   \n",
       "\n",
       "   Relative Humidity [%]  heat_index  hour  month  is_weekday  is_holiday  \\\n",
       "0              42.781847       21.02     1      1           1           0   \n",
       "1              43.350762       20.75     1      1           1           0   \n",
       "2              43.919676       20.48     1      1           1           0   \n",
       "3              44.488591       20.21     1      1           1           0   \n",
       "4              45.057505       19.94     2      1           1           0   \n",
       "\n",
       "   max_load_hourly  max_temp_hourly  min_temp_hourly  bldg_id  \n",
       "0         5.476113             -6.1            -6.55       32  \n",
       "1         5.476113             -6.1            -6.55       32  \n",
       "2         5.476113             -6.1            -6.55       32  \n",
       "3         5.476113             -6.1            -6.55       32  \n",
       "4         5.476113             -6.7            -6.70       32  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35037, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bSKAPs36zk_5"
   },
   "outputs": [],
   "source": [
    "buildings = df['bldg_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): True values.\n",
    "        y_pred (array-like): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "        float: SMAPE value.\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_true - y_pred)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    smape_value = np.mean(numerator / denominator) * 100\n",
    "    return smape_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y_X(df_load):\n",
    "    \"\"\"\n",
    "    Create Y and X variables for linear regression model.\n",
    "\n",
    "    Parameters:\n",
    "        df_load (pandas.DataFrame): DataFrame containing load data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing Y and X variables.  \n",
    "    \"\"\"\n",
    "    for i in range(1, 97):\n",
    "        df_load[f\"shift_{i}\"] = df[\"out.electricity.total.energy_consumption\"].shift(i)\n",
    "\n",
    "    df_load = df_load.dropna()\n",
    "\n",
    "    Y = df_load['out.electricity.total.energy_consumption']\n",
    "    X = df_load.drop(['out.electricity.total.energy_consumption', 'Index', 'bldg_id'], axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return Y, X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, X = create_Y_X(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yeqESu7bnNXx"
   },
   "outputs": [],
   "source": [
    "def train_sgd_regressor(directory, target_column='out.electricity.total.energy_consumption', test_size=0.2, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Train the SGD Regressor model using data from building CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing building CSV files.\n",
    "        target_column (str): The name of the target column.\n",
    "        test_size (float): Proportion of the building files to use for testing.\n",
    "        chunk_size (int): Number of rows to process in each chunk.\n",
    "\n",
    "    Returns:\n",
    "        model: Trained model.\n",
    "        building_pred: Predictions for one building.\n",
    "        building_actual: Actual values for that building.\n",
    "        avg_smape: Average SMAPE across all buildings.\n",
    "        avg_r2: Average R² score across all buildings.\n",
    "    \"\"\"\n",
    "    model = SGDRegressor()\n",
    "\n",
    "    # Lists to store individual SMAPE scores for training and testing\n",
    "    train_smape_list = []\n",
    "    test_smape_list = []\n",
    "\n",
    "    # Use glob to list all CSV files in the directory\n",
    "    csv_files = glob(f\"{directory}/*.csv\")\n",
    "    \n",
    "    # Split building files into train and test sets\n",
    "    train_files, test_files = train_test_split(csv_files, test_size=test_size)\n",
    "\n",
    "    # Training phase: loop over the training set files\n",
    "    for filename in tqdm(train_files, desc=\"Training on buildings\", unit=\"file\"):\n",
    "        try:\n",
    "            # Use chunksize in read_csv to read the file in chunks\n",
    "            for chunk in pd.read_csv(filename, chunksize=chunk_size):\n",
    "                Y, X = create_Y_X(chunk)\n",
    "\n",
    "                # Train the model with the current chunk\n",
    "                model.partial_fit(X, Y)\n",
    "\n",
    "                # Calculate SMAPE on the training chunk and store it\n",
    "                Y_pred_train = model.predict(X)\n",
    "                smape_train = smape(Y, Y_pred_train)\n",
    "                train_smape_list.append(smape_train)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            continue  # Skip to the next file if there's an error\n",
    "\n",
    "    # Testing phase: loop over the test set files\n",
    "    for filename in tqdm(test_files, desc=\"Testing on buildings\", unit=\"file\"):\n",
    "        try:\n",
    "            # Use chunksize in read_csv to read the file in chunks\n",
    "            for chunk in pd.read_csv(filename, chunksize=chunk_size):\n",
    "                Y, X = create_Y_X(chunk)\n",
    "\n",
    "                # Make predictions on the current chunk\n",
    "                Y_pred = model.predict(X)\n",
    "\n",
    "                # Compute SMAPE for the current test building\n",
    "                smape_value = smape(Y, Y_pred)\n",
    "                test_smape_list.append(smape_value)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            continue  # Skip to the next file if there's an error\n",
    "\n",
    "    # Compute average SMAPE for training and testing\n",
    "    avg_train_smape = np.mean(train_smape_list)\n",
    "    avg_test_smape = np.mean(test_smape_list)\n",
    "\n",
    "    return model, test_files, avg_train_smape, avg_test_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqZWhJknowgN",
    "outputId": "68219059-3db1-4a63-b319-beeb6775556f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on buildings:   0%|          | 11/5120 [00:07<57:29,  1.48file/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shift_30'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/frame.py:4485\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4485\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4487\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shift_30'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, testfiles, avg_train_smape, avg_test_smape \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sgd_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 35\u001b[0m, in \u001b[0;36mtrain_sgd_regressor\u001b[0;34m(directory, target_column, test_size, chunk_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Use chunksize in read_csv to read the file in chunks\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(filename, chunksize\u001b[38;5;241m=\u001b[39mchunk_size):\n\u001b[0;32m---> 35\u001b[0m         Y, X \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_Y_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# Train the model with the current chunk\u001b[39;00m\n\u001b[1;32m     38\u001b[0m         model\u001b[38;5;241m.\u001b[39mpartial_fit(X, Y)\n",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m, in \u001b[0;36mcreate_Y_X\u001b[0;34m(df_load)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mCreate Y and X variables for linear regression model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    tuple: Tuple containing Y and X variables.  \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m97\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mdf_load\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshift_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout.electricity.total.energy_consumption\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(i)\n\u001b[1;32m     14\u001b[0m df_load \u001b[38;5;241m=\u001b[39m df_load\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     16\u001b[0m Y \u001b[38;5;241m=\u001b[39m df_load[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.electricity.total.energy_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4535\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   4536\u001b[0m             refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4538\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/frame.py:4488\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4485\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4487\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 4488\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1365\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m   1359\u001b[0m     \u001b[38;5;66;03m# TODO: re-issue this with setitem-specific message?\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of Index.insert with object-dtype is deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1363\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1364\u001b[0m     )\n\u001b[0;32m-> 1365\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1368\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/Downloads/Projects/FermataEnergy_BTTStudio/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6988\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6986\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(res_values, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   6987\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6988\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_fill_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   6990\u001b[0m     \u001b[38;5;66;03m# e.g. trying to insert an integer into a DatetimeIndex\u001b[39;00m\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;66;03m#  We cannot keep the same dtype, so cast to the (often object)\u001b[39;00m\n\u001b[1;32m   6992\u001b[0m     \u001b[38;5;66;03m#  minimal shared dtype before doing the insert.\u001b[39;00m\n\u001b[1;32m   6993\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_common_type_compat(item)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, testfiles, avg_train_smape, avg_test_smape = train_sgd_regressor(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression:\n",
    "Average SMAPE: 87.80732828774465\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.9999737802848\n"
     ]
    }
   ],
   "source": [
    "print(avg_test_smape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.9999950668809\n"
     ]
    }
   ],
   "source": [
    "print(avg_train_smape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
