{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_path = '/Users/veronica/Library/CloudStorage/GoogleDrive-veronicahangsan@gmail.com/.shortcut-targets-by-id/1FsOPywSgK_wZmrVrSTBVi4q8G3Mg_yMJ/Team-Fermata-Energy/processed_data/md_one_hot_encoded_subset20.csv'\n",
    "PATH = '/Users/veronica/Library/CloudStorage/GoogleDrive-veronicahangsan@gmail.com/.shortcut-targets-by-id/1FsOPywSgK_wZmrVrSTBVi4q8G3Mg_yMJ/Team-Fermata-Energy/processed_data/processed_weather_load_w_timestamp/'\n",
    "json_file = '../data/subset20_20_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv(md_path)\n",
    "with open(json_file, 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bldg_ids = [filename.split('.')[0] for filename in json_data.get(\"train_bldg_ids\", [])]\n",
    "test_bldg_ids = [filename.split('.')[0] for filename in json_data.get(\"test_bldg_ids\", [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md['bldg_id'] = md['bldg_id'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_buildings = md[md['in.comstock_building_type_group_Education'] == 1]\n",
    "hot_dry_buildings = md[md['in.building_america_climate_zone_Mixed-Humid'] == 1]\n",
    "edu_and_mixed_humid = education_buildings.merge(hot_dry_buildings, on='bldg_id', how='inner')\n",
    "edu_and_mixed_humid_bldg_ids = edu_and_mixed_humid['bldg_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Buildings categorized as Education and in 'Hot-Dry' zone: {edu_and_mixed_humid_bldg_ids[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_train_bldgs = set(train_bldg_ids).intersection(edu_and_mixed_humid_bldg_ids)\n",
    "valid_test_bldgs = set(test_bldg_ids).intersection(edu_and_mixed_humid_bldg_ids)\n",
    "\n",
    "print(f\"Valid train buildings (Education + Mixed-Humid): {valid_train_bldgs}\")\n",
    "print(f\"Valid test buildings (Education + Mixed-Humid): {valid_test_bldgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of valid training buildings: {len(valid_train_bldgs)}\")\n",
    "print(f\"Number of valid testing buildings: {len(valid_test_bldgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_building(filename, directory):\n",
    "    try:\n",
    "        file_path = f\"{directory}/{filename}.csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {filename}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_building(df_load, md):\n",
    "    \"\"\"\n",
    "    Prepare features (X) and target (y) for training the model.\n",
    "    \"\"\"\n",
    "    df_load['bldg_id'] = df_load['bldg_id'].astype(str)\n",
    "    md['bldg_id'] = md['bldg_id'].astype(str)\n",
    "\n",
    "    # Create lag features\n",
    "    for i in range(1, 97):\n",
    "        df_load[f\"shift_{i}\"] = df_load[\"out.electricity.total.energy_consumption\"].shift(i)\n",
    "\n",
    "    # Process timestamp if available\n",
    "    if 'timestamp' in df_load.columns:\n",
    "        df_load['timestamp'] = pd.to_datetime(df_load['timestamp'])\n",
    "        datetime_columns = {\n",
    "            'hour': df_load['timestamp'].dt.hour,\n",
    "            'day_of_week': df_load['timestamp'].dt.dayofweek,\n",
    "            'day_of_year': df_load['timestamp'].dt.dayofyear,\n",
    "            'month': df_load['timestamp'].dt.month,\n",
    "            'year': df_load['timestamp'].dt.year\n",
    "        }\n",
    "        df_load = pd.concat([df_load, pd.DataFrame(datetime_columns)], axis=1)\n",
    "        df_load = df_load.drop(columns=['timestamp'])  # drop timestamp column\n",
    "\n",
    "    # Merge with metadata\n",
    "    merged_df = df_load.merge(md, on='bldg_id', how='left')\n",
    "    merged_df = merged_df.drop(['bldg_id'], axis=1)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    merged_df = merged_df.dropna()\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(actual, predicted):\n",
    "    actual, predicted = np.array(actual), np.array(predicted)\n",
    "    denominator = np.abs(actual) + np.abs(predicted)\n",
    "    diff = np.abs(actual - predicted) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return 200 * np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_model(directory, valid_train_bldgs, valid_test_bldgs, target_column='out.electricity.total.energy_consumption'):\n",
    "    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "    from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=15, max_depth=4, min_samples_split=15, min_samples_leaf=10, random_state=42, n_jobs=1)\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    ensemble_model = VotingRegressor(estimators=[('rf', rf_model), ('gb', gb_model)])\n",
    "\n",
    "    smape_train_list = []\n",
    "    smape_test_list = []\n",
    "\n",
    "    for building_id in valid_train_bldgs:\n",
    "        train_df = load_data_for_building(building_id, directory)\n",
    "        if train_df is not None and target_column in train_df:\n",
    "            train_df_prepared = prepare_data_for_building(train_df, md)\n",
    "            if train_df_prepared is not None and len(train_df_prepared) > 0:\n",
    "                X_train = train_df_prepared.drop(columns=[target_column])\n",
    "                y_train = train_df_prepared[target_column]\n",
    "                ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "                y_train_pred = ensemble_model.predict(X_train)\n",
    "                smape_train = smape(y_train, y_train_pred)\n",
    "                smape_train_list.append(smape_train)\n",
    "            else:\n",
    "                print(f\"Prepared data is empty for {building_id}\")\n",
    "\n",
    "    for building_id in valid_test_bldgs:\n",
    "        test_df = load_data_for_building(building_id, directory)\n",
    "        if test_df is not None and target_column in test_df:\n",
    "            test_df_prepared = prepare_data_for_building(test_df, md)\n",
    "            if test_df_prepared is not None and len(test_df_prepared) > 0:\n",
    "                X_test = test_df_prepared.drop(columns=[target_column])\n",
    "                y_test = test_df_prepared[target_column]\n",
    "                y_test_pred = ensemble_model.predict(X_test)\n",
    "                smape_test = smape(y_test, y_test_pred)\n",
    "                smape_test_list.append(smape_test)\n",
    "\n",
    "    avg_smape_train = np.mean(smape_train_list)\n",
    "    avg_smape_test = np.mean(smape_test_list)\n",
    "    print(f\"Average SMAPE (training set): {avg_smape_train:.4f}\")\n",
    "    print(f\"Average SMAPE (testing set): {avg_smape_test:.4f}\")\n",
    "    return ensemble_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_random_forest_model(PATH, valid_train_bldgs, valid_test_bldgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_24_hour_predictions(building_ids, directory, model, target_column='out.electricity.total.energy_consumption'):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, building_id in enumerate(building_ids[:5]):\n",
    "        df = load_data_for_building(building_id, directory)\n",
    "        if df is not None:\n",
    "            df_prepared = prepare_data_for_building(df, md)\n",
    "\n",
    "            if df_prepared is not None and len(df_prepared) > 48:\n",
    "                X = df_prepared.drop(columns=[target_column])\n",
    "                y_actual = df_prepared[target_column]\n",
    "\n",
    "                # last 24 hours for prediction\n",
    "                X_last_24 = X.iloc[-24:]\n",
    "                y_actual_last_24 = y_actual.iloc[-24:]\n",
    "                \n",
    "                #  next 24 hours\n",
    "                X_next_24 = X.iloc[-24:].copy()\n",
    "                y_next_24_pred = model.predict(X_next_24)\n",
    "\n",
    "                timestamps = np.arange(24)\n",
    "                \n",
    "                # actual vs predicted for the next 24 hours\n",
    "                plt.subplot(3, 2, i + 1)\n",
    "                plt.plot(timestamps, y_actual_last_24, label='Actual (Last 24h)', color='blue')\n",
    "                plt.plot(timestamps, y_next_24_pred, label='Predicted (Next 24h)', color='red', linestyle=\"--\")\n",
    "                plt.title(f'Building ID: {building_id}')\n",
    "                plt.xlabel('Hours')\n",
    "                plt.ylabel('Electricity Consumption')\n",
    "                plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
